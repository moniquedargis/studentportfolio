{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEIS763 Team Project:  Machine Learning Regression Analysis of a Thermal Asperity Detector\n",
    "Team Members:\n",
    "Monique Dargis\n",
    "Erik Hutchinson\n",
    "Connor Mills\n",
    "Derek Synan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107432, 28)\n",
      "WFR_X_UM           int64\n",
      "WFR_Y_UM           int64\n",
      "WFR_X_IN_CUBE      int64\n",
      "WFR_Y_IN_CUBE      int64\n",
      "WFR_CUBE_NUM      object\n",
      "BAR_ID            object\n",
      "HEAD_ID           object\n",
      "WAFER_ID          object\n",
      "PROD_CODE         object\n",
      "PHOTO_TOOL        object\n",
      "PHOTOMASK         object\n",
      "OVL-Y_TOOL        object\n",
      "OVL-Y_DELTA      float64\n",
      "SEM_TOOL          object\n",
      "SEM_DELTA        float64\n",
      "PROM_TOOL         object\n",
      "PROM_DELTA       float64\n",
      "XRF_TOOL          object\n",
      "XRF_DELTA        float64\n",
      "MILL_TOOL         object\n",
      "WAFER_TAD_RES    float64\n",
      "ISI_TESTER        object\n",
      "ESTBP            float64\n",
      "ELG_SH_DELTA     float64\n",
      "LAP_TOOL          object\n",
      "HGA_TESTER        object\n",
      "HGA_RES          float64\n",
      "HGA_PF            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Loading the dataset\n",
    "df=pd.read_csv(\"TADsampleResPF.csv\")\n",
    "\n",
    "# Correct Column Datatypes\n",
    "df[\"WFR_CUBE_NUM\"]=df.WFR_CUBE_NUM.astype(str)\n",
    "df[\"PHOTOMASK\"]=df.PHOTOMASK.astype(str)\n",
    "df[\"ISI_TESTER\"]=df.ISI_TESTER.astype(str)\n",
    "df[\"LAP_TOOL\"]=df.LAP_TOOL.astype(str)\n",
    "df[\"HGA_PF\"]=df.HGA_PF.astype(str)\n",
    "\n",
    "# Verify the dataframe size & datatypes for the columns\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGA_RES</th>\n",
       "      <th>HGA_PF</th>\n",
       "      <th>WFR_X_UM</th>\n",
       "      <th>WFR_Y_UM</th>\n",
       "      <th>WFR_X_IN_CUBE</th>\n",
       "      <th>WFR_Y_IN_CUBE</th>\n",
       "      <th>WFR_CUBE_NUM</th>\n",
       "      <th>BAR_ID</th>\n",
       "      <th>HEAD_ID</th>\n",
       "      <th>WAFER_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>PROM_DELTA</th>\n",
       "      <th>XRF_TOOL</th>\n",
       "      <th>XRF_DELTA</th>\n",
       "      <th>MILL_TOOL</th>\n",
       "      <th>WAFER_TAD_RES</th>\n",
       "      <th>ISI_TESTER</th>\n",
       "      <th>ESTBP</th>\n",
       "      <th>ELG_SH_DELTA</th>\n",
       "      <th>LAP_TOOL</th>\n",
       "      <th>HGA_TESTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.3247</td>\n",
       "      <td>1</td>\n",
       "      <td>23101</td>\n",
       "      <td>-45899</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>25.846148</td>\n",
       "      <td>112.0</td>\n",
       "      <td>91.020</td>\n",
       "      <td>-3.955</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.2121</td>\n",
       "      <td>1</td>\n",
       "      <td>-2309</td>\n",
       "      <td>-84299</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>0Y</td>\n",
       "      <td>K1</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>27.420664</td>\n",
       "      <td>162.0</td>\n",
       "      <td>113.205</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87.7450</td>\n",
       "      <td>1</td>\n",
       "      <td>-66219</td>\n",
       "      <td>49801</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>EM</td>\n",
       "      <td>X1</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>25.870705</td>\n",
       "      <td>173.0</td>\n",
       "      <td>102.549</td>\n",
       "      <td>-1029.000</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR492A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.1483</td>\n",
       "      <td>0</td>\n",
       "      <td>21561</td>\n",
       "      <td>15301</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "      <td>6F</td>\n",
       "      <td>F0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>26.264261</td>\n",
       "      <td>120.0</td>\n",
       "      <td>114.428</td>\n",
       "      <td>-1029.000</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.6131</td>\n",
       "      <td>1</td>\n",
       "      <td>18481</td>\n",
       "      <td>51001</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>221</td>\n",
       "      <td>9Q</td>\n",
       "      <td>J0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>25.581217</td>\n",
       "      <td>132.0</td>\n",
       "      <td>93.245</td>\n",
       "      <td>-2.109</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    HGA_RES HGA_PF  WFR_X_UM  WFR_Y_UM  WFR_X_IN_CUBE  WFR_Y_IN_CUBE  \\\n",
       "0   93.3247      1     23101    -45899              5             28   \n",
       "1   90.2121      1     -2309    -84299             10             35   \n",
       "2   87.7450      1    -66219     49801              9             32   \n",
       "3  111.1483      0     21561     15301              7              7   \n",
       "4   91.6131      1     18481     51001             11             36   \n",
       "\n",
       "  WFR_CUBE_NUM BAR_ID HEAD_ID WAFER_ID  ... PROM_DELTA XRF_TOOL XRF_DELTA  \\\n",
       "0           88     C0      D0    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "1           29     0Y      K1    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "2          213     EM      X1    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "3          183     6F      F0    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "4          221     9Q      J0    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "\n",
       "  MILL_TOOL  WAFER_TAD_RES ISI_TESTER    ESTBP ELG_SH_DELTA  LAP_TOOL  \\\n",
       "0    NXE_51      25.846148      112.0   91.020       -3.955    4263.0   \n",
       "1    NXE_51      27.420664      162.0  113.205       -0.073    4263.0   \n",
       "2    NXE_51      25.870705      173.0  102.549    -1029.000    4263.0   \n",
       "3    NXE_51      26.264261      120.0  114.428    -1029.000    4263.0   \n",
       "4    NXE_51      25.581217      132.0   93.245       -2.109    4263.0   \n",
       "\n",
       "  HGA_TESTER  \n",
       "0   V3CR375A  \n",
       "1   V3CR375A  \n",
       "2   V3CR492A  \n",
       "3   V3CR375A  \n",
       "4   V3CR375A  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder HGA_RES to front of Dataframe to make the TARGET column easy to find\n",
    "\n",
    "hgares = df['HGA_RES']\n",
    "df.drop(labels=['HGA_RES'], axis=1, inplace = True)\n",
    "df.insert(0, 'HGA_RES', hgares)\n",
    "\n",
    "# Reorder HGA_PF to front of Dataframe to make the TARGET column easy to find\n",
    "\n",
    "hgapf = df['HGA_PF']\n",
    "df.drop(labels=['HGA_PF'], axis=1, inplace = True)\n",
    "df.insert(1, 'HGA_PF', hgapf)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80008, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGA_RES</th>\n",
       "      <th>HGA_PF</th>\n",
       "      <th>WFR_X_UM</th>\n",
       "      <th>WFR_Y_UM</th>\n",
       "      <th>WFR_X_IN_CUBE</th>\n",
       "      <th>WFR_Y_IN_CUBE</th>\n",
       "      <th>WFR_CUBE_NUM</th>\n",
       "      <th>BAR_ID</th>\n",
       "      <th>HEAD_ID</th>\n",
       "      <th>WAFER_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>PROM_DELTA</th>\n",
       "      <th>XRF_TOOL</th>\n",
       "      <th>XRF_DELTA</th>\n",
       "      <th>MILL_TOOL</th>\n",
       "      <th>WAFER_TAD_RES</th>\n",
       "      <th>ISI_TESTER</th>\n",
       "      <th>ESTBP</th>\n",
       "      <th>ELG_SH_DELTA</th>\n",
       "      <th>LAP_TOOL</th>\n",
       "      <th>HGA_TESTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.3247</td>\n",
       "      <td>1</td>\n",
       "      <td>23101</td>\n",
       "      <td>-45899</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>25.846148</td>\n",
       "      <td>112.0</td>\n",
       "      <td>91.020</td>\n",
       "      <td>-3.955</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.2121</td>\n",
       "      <td>1</td>\n",
       "      <td>-2309</td>\n",
       "      <td>-84299</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>0Y</td>\n",
       "      <td>K1</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>27.420664</td>\n",
       "      <td>162.0</td>\n",
       "      <td>113.205</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.6131</td>\n",
       "      <td>1</td>\n",
       "      <td>18481</td>\n",
       "      <td>51001</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>221</td>\n",
       "      <td>9Q</td>\n",
       "      <td>J0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>25.581217</td>\n",
       "      <td>132.0</td>\n",
       "      <td>93.245</td>\n",
       "      <td>-2.109</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>V3CR375A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95.0665</td>\n",
       "      <td>1</td>\n",
       "      <td>-53129</td>\n",
       "      <td>-8699</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>138</td>\n",
       "      <td>KG</td>\n",
       "      <td>G1</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>26.950050</td>\n",
       "      <td>72.0</td>\n",
       "      <td>101.439</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>4266.0</td>\n",
       "      <td>V3CR492A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90.3425</td>\n",
       "      <td>1</td>\n",
       "      <td>-34649</td>\n",
       "      <td>-37799</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>HR</td>\n",
       "      <td>I0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>XRF_54</td>\n",
       "      <td>-4.8858</td>\n",
       "      <td>NXE_51</td>\n",
       "      <td>25.913645</td>\n",
       "      <td>72.0</td>\n",
       "      <td>103.679</td>\n",
       "      <td>0.116</td>\n",
       "      <td>4266.0</td>\n",
       "      <td>V3CR492A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HGA_RES HGA_PF  WFR_X_UM  WFR_Y_UM  WFR_X_IN_CUBE  WFR_Y_IN_CUBE  \\\n",
       "0  93.3247      1     23101    -45899              5             28   \n",
       "1  90.2121      1     -2309    -84299             10             35   \n",
       "4  91.6131      1     18481     51001             11             36   \n",
       "6  95.0665      1    -53129     -8699              6             17   \n",
       "8  90.3425      1    -34649    -37799             10             10   \n",
       "\n",
       "  WFR_CUBE_NUM BAR_ID HEAD_ID WAFER_ID  ... PROM_DELTA XRF_TOOL XRF_DELTA  \\\n",
       "0           88     C0      D0    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "1           29     0Y      K1    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "4          221     9Q      J0    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "6          138     KG      G1    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "8          102     HR      I0    U8IDG  ...     0.0263   XRF_54   -4.8858   \n",
       "\n",
       "  MILL_TOOL  WAFER_TAD_RES ISI_TESTER    ESTBP ELG_SH_DELTA  LAP_TOOL  \\\n",
       "0    NXE_51      25.846148      112.0   91.020       -3.955    4263.0   \n",
       "1    NXE_51      27.420664      162.0  113.205       -0.073    4263.0   \n",
       "4    NXE_51      25.581217      132.0   93.245       -2.109    4263.0   \n",
       "6    NXE_51      26.950050       72.0  101.439       -0.201    4266.0   \n",
       "8    NXE_51      25.913645       72.0  103.679        0.116    4266.0   \n",
       "\n",
       "  HGA_TESTER  \n",
       "0   V3CR375A  \n",
       "1   V3CR375A  \n",
       "4   V3CR375A  \n",
       "6   V3CR492A  \n",
       "8   V3CR492A  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start Cleaning data\n",
    "\n",
    "# Drop rows with missing data\n",
    "df1 = df.dropna(axis=0)\n",
    "\n",
    "# Remove Outliers\n",
    "\n",
    "df1 = df1.drop(df1[(df1.XRF_DELTA < -10)].index)\n",
    "df1 = df1.drop(df1[(df1.XRF_DELTA > 10)].index)\n",
    "df1 = df1.drop(df1[(df1.WAFER_TAD_RES < 10)].index)\n",
    "df1 = df1.drop(df1[(df1.WAFER_TAD_RES > 50)].index)\n",
    "df1 = df1.drop(df1[(df1.ESTBP < 30)].index)\n",
    "df1 = df1.drop(df1[(df1.ESTBP > 180)].index)\n",
    "df1 = df1.drop(df1[(df1.ELG_SH_DELTA < -10)].index)\n",
    "df1 = df1.drop(df1[(df1.ELG_SH_DELTA > 10)].index)\n",
    "df1 = df1.drop(df1[(df1.HGA_RES < 50)].index)\n",
    "df1 = df1.drop(df1[(df1.HGA_RES > 150)].index)\n",
    "\n",
    "print(df1.shape)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80008, 400)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGA_RES</th>\n",
       "      <th>HGA_PF</th>\n",
       "      <th>WFR_X_UM</th>\n",
       "      <th>WFR_Y_UM</th>\n",
       "      <th>WFR_X_IN_CUBE</th>\n",
       "      <th>WFR_Y_IN_CUBE</th>\n",
       "      <th>WFR_CUBE_NUM</th>\n",
       "      <th>BAR_ID</th>\n",
       "      <th>HEAD_ID</th>\n",
       "      <th>WAFER_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>HGA_TESTER_V3CR970A</th>\n",
       "      <th>HGA_TESTER_V3CR977A</th>\n",
       "      <th>HGA_TESTER_V3CR980A</th>\n",
       "      <th>HGA_TESTER_V3CR990A</th>\n",
       "      <th>HGA_TESTER_V3CR991A</th>\n",
       "      <th>HGA_TESTER_V3CR992A</th>\n",
       "      <th>HGA_TESTER_V3CR999A</th>\n",
       "      <th>HGA_TESTER_V3CRA59A</th>\n",
       "      <th>HGA_TESTER_V6CR387A</th>\n",
       "      <th>HGA_TESTER_V6CR904A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.3247</td>\n",
       "      <td>1</td>\n",
       "      <td>23101</td>\n",
       "      <td>-45899</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.2121</td>\n",
       "      <td>1</td>\n",
       "      <td>-2309</td>\n",
       "      <td>-84299</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>0Y</td>\n",
       "      <td>K1</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.6131</td>\n",
       "      <td>1</td>\n",
       "      <td>18481</td>\n",
       "      <td>51001</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>221</td>\n",
       "      <td>9Q</td>\n",
       "      <td>J0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95.0665</td>\n",
       "      <td>1</td>\n",
       "      <td>-53129</td>\n",
       "      <td>-8699</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>138</td>\n",
       "      <td>KG</td>\n",
       "      <td>G1</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90.3425</td>\n",
       "      <td>1</td>\n",
       "      <td>-34649</td>\n",
       "      <td>-37799</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "      <td>HR</td>\n",
       "      <td>I0</td>\n",
       "      <td>U8IDG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HGA_RES HGA_PF  WFR_X_UM  WFR_Y_UM  WFR_X_IN_CUBE  WFR_Y_IN_CUBE  \\\n",
       "0  93.3247      1     23101    -45899              5             28   \n",
       "1  90.2121      1     -2309    -84299             10             35   \n",
       "4  91.6131      1     18481     51001             11             36   \n",
       "6  95.0665      1    -53129     -8699              6             17   \n",
       "8  90.3425      1    -34649    -37799             10             10   \n",
       "\n",
       "  WFR_CUBE_NUM BAR_ID HEAD_ID WAFER_ID  ... HGA_TESTER_V3CR970A  \\\n",
       "0           88     C0      D0    U8IDG  ...                   0   \n",
       "1           29     0Y      K1    U8IDG  ...                   0   \n",
       "4          221     9Q      J0    U8IDG  ...                   0   \n",
       "6          138     KG      G1    U8IDG  ...                   0   \n",
       "8          102     HR      I0    U8IDG  ...                   0   \n",
       "\n",
       "   HGA_TESTER_V3CR977A  HGA_TESTER_V3CR980A  HGA_TESTER_V3CR990A  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "6                    0                    0                    0   \n",
       "8                    0                    0                    0   \n",
       "\n",
       "   HGA_TESTER_V3CR991A  HGA_TESTER_V3CR992A  HGA_TESTER_V3CR999A  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "6                    0                    0                    0   \n",
       "8                    0                    0                    0   \n",
       "\n",
       "   HGA_TESTER_V3CRA59A  HGA_TESTER_V6CR387A  HGA_TESTER_V6CR904A  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    0  \n",
       "4                    0                    0                    0  \n",
       "6                    0                    0                    0  \n",
       "8                    0                    0                    0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Columns for Categorical Values\n",
    "\n",
    "df1_dummies = pd.get_dummies(df1, columns=[\"PHOTO_TOOL\"])\n",
    "df2_dummies = pd.get_dummies(df1_dummies, columns=[\"PHOTOMASK\"])\n",
    "df3_dummies = pd.get_dummies(df2_dummies, columns=[\"OVL-Y_TOOL\"])\n",
    "df4_dummies = pd.get_dummies(df3_dummies, columns=[\"SEM_TOOL\"])\n",
    "df5_dummies = pd.get_dummies(df4_dummies, columns=[\"PROM_TOOL\"])\n",
    "df6_dummies = pd.get_dummies(df5_dummies, columns=[\"XRF_TOOL\"])\n",
    "df7_dummies = pd.get_dummies(df6_dummies, columns=[\"MILL_TOOL\"])\n",
    "df8_dummies = pd.get_dummies(df7_dummies, columns=[\"ISI_TESTER\"])\n",
    "df9_dummies = pd.get_dummies(df8_dummies, columns=[\"LAP_TOOL\"])\n",
    "df10_dummies = pd.get_dummies(df9_dummies, columns=[\"HGA_TESTER\"])\n",
    "\n",
    "print(df10_dummies.shape)\n",
    "df10_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Independent & Dependent Variables\n",
    "\n",
    "X = df10_dummies.iloc[:,11:400] \n",
    "y1 = df10_dummies.iloc[:,0].values  # Numerical Target\n",
    "y2 = df10_dummies.iloc[:,1].values  # Pass/Fail Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the features \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_std = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define logistic regression object\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logRegObj = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#K-fold Cross Validation - Logistic regression with all features\n",
    "from sklearn.model_selection import cross_val_score\n",
    "modelAccuracies_logreg = cross_val_score(estimator=logRegObj, X=X_std, y=y2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression all components\n",
      "Model Accuracy mean\n",
      "0.8389779590051244\n",
      "Model Accuracy SD\n",
      "0.056573480069297924\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression all components\")\n",
    "print(\"Model Accuracy mean\")\n",
    "print(modelAccuracies_logreg.mean())\n",
    "print(\"Model Accuracy SD\")\n",
    "print(modelAccuracies_logreg.std())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Perform stepwise selection to reduce number of features included in regression model\n",
    "#NOTE: For demonstration purposes only. Do NOT run - takes a very long time\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "#Code takes non-normalized data\n",
    "result = stepwise_selection(X, y2)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#If running Stepwise elimination cell above, can use following lines:\n",
    "\n",
    "X_reduced = X[result]\n",
    "\n",
    "print(X_reduced.shape)\n",
    "\n",
    "#Else, run cell below to avoid need to run Stepwise elimination code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80008, 171)\n"
     ]
    }
   ],
   "source": [
    "#Reduce features based on Stepwise elimination\n",
    "\n",
    "reduced_columns = ['ELG_SH_DELTA', 'OVL-Y_TOOL_ARC_60', 'OVL-Y_DELTA', 'SEM_TOOL_SEM_62', 'ESTBP', 'SEM_DELTA', 'WAFER_TAD_RES', 'OVL-Y_TOOL_ARC_59', 'PHOTO_TOOL_ASM_52', 'HGA_TESTER_V3CR235A', 'LAP_TOOL_4287.0', 'LAP_TOOL_4280.0', 'LAP_TOOL_4288.0', 'LAP_TOOL_4191.0', 'LAP_TOOL_4192.0', 'LAP_TOOL_4258.0', 'LAP_TOOL_4259.0', 'LAP_TOOL_4281.0', 'LAP_TOOL_4190.0', 'LAP_TOOL_4279.0', 'LAP_TOOL_4187.0', 'LAP_TOOL_4295.0', 'LAP_TOOL_4180.0', 'LAP_TOOL_4170.0', 'LAP_TOOL_4268.0', 'LAP_TOOL_4261.0', 'LAP_TOOL_4265.0', 'LAP_TOOL_4001.0', 'LAP_TOOL_4171.0', 'HGA_TESTER_V3CR817A', 'LAP_TOOL_4296.0', 'HGA_TESTER_V6CR904A', 'HGA_TESTER_V6CR387A', 'OVL-Y_TOOL_ARC_57', 'HGA_TESTER_V3CR492A', 'HGA_TESTER_V3CR330A', 'HGA_TESTER_V3CR302A', 'HGA_TESTER_V3CR886A', 'MILL_TOOL_NXE_51', 'HGA_TESTER_V3CR608A', 'HGA_TESTER_V3CR790A', 'HGA_TESTER_V3CR103A', 'ISI_TESTER_183.0', 'LAP_TOOL_4186.0', 'HGA_TESTER_V3CR473A', 'HGA_TESTER_V3CR764A', 'LAP_TOOL_4018.0', 'HGA_TESTER_V3CR301A', 'HGA_TESTER_V3CR357A', 'HGA_TESTER_V3CR759A', 'ISI_TESTER_114.0', 'HGA_TESTER_V3CR364A', 'XRF_DELTA', 'HGA_TESTER_V3CR375A', 'HGA_TESTER_V3CR670A', 'HGA_TESTER_V3CR456A', 'HGA_TESTER_V3CR907A', 'HGA_TESTER_V3CR246A', 'HGA_TESTER_V3CR521A', 'HGA_TESTER_V3CR747A', 'HGA_TESTER_V3CR776A', 'HGA_TESTER_V3CR320A', 'HGA_TESTER_V3CR525A', 'HGA_TESTER_V3CR683A', 'HGA_TESTER_V3CR822A', 'HGA_TESTER_V3CR647A', 'HGA_TESTER_V3CR236A', 'HGA_TESTER_V3CR512A', 'HGA_TESTER_V3CR727A', 'HGA_TESTER_V3CR528A', 'HGA_TESTER_V3CR185A', 'LAP_TOOL_4262.0', 'HGA_TESTER_V3CR399A', 'HGA_TESTER_V3CR642A', 'HGA_TESTER_V3CR672A', 'LAP_TOOL_4264.0', 'HGA_TESTER_V3CR930A', 'HGA_TESTER_V3CR171A', 'ISI_TESTER_84.0', 'HGA_TESTER_V3CR735A', 'HGA_TESTER_V3CR141A', 'HGA_TESTER_V3CR936A', 'OVL-Y_TOOL_ARC_55', 'HGA_TESTER_V3CR980A', 'HGA_TESTER_V3CR774A', 'HGA_TESTER_V3CR436A', 'ISI_TESTER_184.0', 'HGA_TESTER_V3CR409A', 'SEM_TOOL_SEM_69', 'HGA_TESTER_V3CR859A', 'HGA_TESTER_V3CR826A', 'HGA_TESTER_V3CR754A', 'HGA_TESTER_V3CR838A', 'HGA_TESTER_V3CR796A', 'ISI_TESTER_179.0', 'HGA_TESTER_V3CR201A', 'HGA_TESTER_V3CR697A', 'ISI_TESTER_135.0', 'HGA_TESTER_V3CR671A', 'HGA_TESTER_V3CR902A', 'HGA_TESTER_V3CR386A', 'HGA_TESTER_V3CR342A', 'HGA_TESTER_V3CR928A', 'HGA_TESTER_V3CR740A', 'HGA_TESTER_V3CR179A', 'HGA_TESTER_V3CR686A', 'HGA_TESTER_V3CR404A', 'HGA_TESTER_V3CR682A', 'HGA_TESTER_V3CR131A', 'HGA_TESTER_V3CR949A', 'HGA_TESTER_V3CR350A', 'HGA_TESTER_V3CR719A', 'HGA_TESTER_V3CR356A', 'HGA_TESTER_V3CR937A', 'HGA_TESTER_V3CR903A', 'HGA_TESTER_V3CR169A', 'HGA_TESTER_V3CR135A', 'HGA_TESTER_V3CR245A', 'HGA_TESTER_V3CR797A', 'HGA_TESTER_V3CR716A', 'HGA_TESTER_V3CR348A', 'HGA_TESTER_V3CR140A', 'HGA_TESTER_V3CR341A', 'HGA_TESTER_V3CR893A', 'HGA_TESTER_V3CR694A', 'HGA_TESTER_V3CR305A', 'HGA_TESTER_V3CR706A', 'HGA_TESTER_V3CR715A', 'HGA_TESTER_V3CR347A', 'HGA_TESTER_V3CR848A', 'HGA_TESTER_V3CR466A', 'HGA_TESTER_V3CR939A', 'HGA_TESTER_V3CR906A', 'HGA_TESTER_V3CR206A', 'ISI_TESTER_164.0', 'ISI_TESTER_129.0', 'ISI_TESTER_25.0', 'HGA_TESTER_V3CR955A', 'ISI_TESTER_113.0', 'ISI_TESTER_239.0', 'ISI_TESTER_58.0', 'LAP_TOOL_4292.0', 'LAP_TOOL_4175.0', 'LAP_TOOL_4195.0', 'LAP_TOOL_4267.0', 'HGA_TESTER_V3CR150A', 'ISI_TESTER_222.0', 'ISI_TESTER_99.0', 'HGA_TESTER_V3CR954A', 'ISI_TESTER_143.0', 'OVL-Y_TOOL_ARC_07', 'ISI_TESTER_94.0', 'ISI_TESTER_190.0', 'ISI_TESTER_176.0', 'ISI_TESTER_124.0', 'HGA_TESTER_V3CR319A', 'LAP_TOOL_4002.0', 'ISI_TESTER_251.0', 'HGA_TESTER_V3CR922A', 'ISI_TESTER_181.0', 'ISI_TESTER_130.0', 'ISI_TESTER_97.0', 'HGA_TESTER_V3CR192A', 'ISI_TESTER_46.0', 'ISI_TESTER_146.0', 'HGA_TESTER_V3CR373A', 'ISI_TESTER_228.0', 'HGA_TESTER_V3CRA59A', 'HGA_TESTER_V3CR990A', 'HGA_TESTER_V3CR635A', 'ISI_TESTER_187.0']\n",
    "\n",
    "X_reduced = X[reduced_columns]\n",
    "\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the features - X_reduced\n",
    "\n",
    "X_reduced_std = sc_X.fit_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#K-fold Cross Validation on features reduced by stepwise elimination using Logistic Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "modelAccuracies_logreg_stepwise = cross_val_score(estimator=logRegObj, X=X_reduced_std, y=y2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression after stepwise reduction\n",
      "Model Accuracy mean\n",
      "0.8472897372203475\n",
      "Model Accuracy SD\n",
      "0.05273843707788392\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression after stepwise reduction\")\n",
    "print(\"Model Accuracy mean\")\n",
    "print(modelAccuracies_logreg_stepwise.mean())\n",
    "print(\"Model Accuracy SD\")\n",
    "print(modelAccuracies_logreg_stepwise.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pcaObj = PCA(n_components=None)\n",
    "X_PCA = pcaObj.fit_transform(X_std)\n",
    "components_variance_PCA = pcaObj.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Variance:\n",
      "1 0.02330601783222712 0.02330601783222712\n",
      "2 0.014542840783181089 0.03784885861540821\n",
      "3 0.009100512379268772 0.046949370994676984\n",
      "4 0.00833833853733687 0.055287709532013854\n",
      "5 0.006815561379732501 0.062103270911746354\n",
      "6 0.006327515598519718 0.06843078651026607\n",
      "7 0.005978566429875327 0.0744093529401414\n",
      "8 0.005458575812375147 0.07986792875251654\n",
      "9 0.005241486739391252 0.08510941549190779\n",
      "10 0.0048824322414959456 0.08999184773340373\n",
      "11 0.004573208363648469 0.0945650560970522\n",
      "12 0.004214548129381404 0.0987796042264336\n",
      "13 0.0038421019676662823 0.10262170619409988\n",
      "14 0.003546099554813824 0.10616780574891371\n",
      "15 0.003474830015515398 0.1096426357644291\n",
      "16 0.003447323507851758 0.11308995927228087\n",
      "17 0.003419197576765114 0.11650915684904599\n",
      "18 0.003361155137938062 0.11987031198698406\n",
      "19 0.003298416185917815 0.12316872817290188\n",
      "20 0.0032529853399525027 0.1264217135128544\n",
      "21 0.0032118376578215264 0.1296335511706759\n",
      "22 0.003173924171874245 0.13280747534255014\n",
      "23 0.003149443906199459 0.13595691924874959\n",
      "24 0.0031232318989655138 0.1390801511477151\n",
      "25 0.003109767082807358 0.14218991823052246\n",
      "26 0.003100496482348243 0.1452904147128707\n",
      "27 0.003097025981645921 0.14838744069451665\n",
      "28 0.0030784574289762874 0.15146589812349293\n",
      "29 0.003077918593822818 0.15454381671731574\n",
      "30 0.003054695580026259 0.15759851229734198\n",
      "31 0.0030374836773379823 0.16063599597467995\n",
      "32 0.003027300398218512 0.16366329637289848\n",
      "33 0.0030211515681866008 0.16668444794108508\n",
      "34 0.0030153090037965216 0.1696997569448816\n",
      "35 0.0030012972166116115 0.1727010541614932\n",
      "36 0.0029916370274086345 0.17569269118890182\n",
      "37 0.0029845048929445367 0.17867719608184635\n",
      "38 0.0029744434262883902 0.18165163950813473\n",
      "39 0.0029610822457698765 0.1846127217539046\n",
      "40 0.0029606504486896076 0.1875733722025942\n",
      "41 0.0029522936807613396 0.19052566588335554\n",
      "42 0.0029504788376136484 0.1934761447209692\n",
      "43 0.002942095042572851 0.19641823976354203\n",
      "44 0.002933475346255067 0.1993517151097971\n",
      "45 0.002929122746976817 0.20228083785677392\n",
      "46 0.0029216004860180165 0.20520243834279195\n",
      "47 0.0029210906940230967 0.20812352903681505\n",
      "48 0.0029112824405435694 0.2110348114773586\n",
      "49 0.0029052528131731812 0.2139400642905318\n",
      "50 0.0028998934850410565 0.21683995777557286\n",
      "51 0.0028981955184749176 0.21973815329404778\n",
      "52 0.0028908562999272113 0.222629009593975\n",
      "53 0.0028876857586121367 0.22551669535258714\n",
      "54 0.002882338142725945 0.2283990334953131\n",
      "55 0.0028755567569838172 0.2312745902522969\n",
      "56 0.002872799364766624 0.23414738961706352\n",
      "57 0.002871997453850416 0.23701938707091394\n",
      "58 0.0028679468972847445 0.2398873339681987\n",
      "59 0.002866310509562061 0.24275364447776077\n",
      "60 0.0028624881059019737 0.24561613258366274\n",
      "61 0.0028616333702957456 0.24847776595395848\n",
      "62 0.0028538012490601887 0.2513315672030187\n",
      "63 0.002848106781835902 0.2541796739848546\n",
      "64 0.0028451903526465197 0.2570248643375011\n",
      "65 0.0028412673197727376 0.25986613165727385\n",
      "66 0.002836919117685671 0.26270305077495953\n",
      "67 0.00283615081237937 0.2655392015873389\n",
      "68 0.0028305952464787684 0.2683697968338177\n",
      "69 0.0028277537694923575 0.27119755060331\n",
      "70 0.0028264261661712607 0.27402397676948126\n",
      "71 0.002821126298308388 0.27684510306778964\n",
      "72 0.0028195688235491912 0.2796646718913388\n",
      "73 0.0028135085295059067 0.2824781804208447\n",
      "74 0.002811060991408413 0.28528924141225315\n",
      "75 0.0028087467240601295 0.28809798813631327\n",
      "76 0.0028054187144000765 0.29090340685071336\n",
      "77 0.002803377528248179 0.2937067843789615\n",
      "78 0.0028029406078012194 0.29650972498676276\n",
      "79 0.0028001784866559334 0.2993099034734187\n",
      "80 0.0027928150217549938 0.30210271849517367\n",
      "81 0.002789390828147175 0.30489210932332084\n",
      "82 0.002788520469094858 0.30768062979241567\n",
      "83 0.002782900258258791 0.31046353005067445\n",
      "84 0.0027811087453925914 0.31324463879606707\n",
      "85 0.002778537705151582 0.31602317650121864\n",
      "86 0.0027757561052918953 0.31879893260651054\n",
      "87 0.002771838904047578 0.32157077151055813\n",
      "88 0.0027702731264962364 0.3243410446370544\n",
      "89 0.0027686638018769414 0.32710970843893133\n",
      "90 0.0027664132367126045 0.32987612167564395\n",
      "91 0.0027648465194745034 0.33264096819511846\n",
      "92 0.0027613790888511487 0.3354023472839696\n",
      "93 0.0027585843017533277 0.33816093158572297\n",
      "94 0.002755736126655418 0.3409166677123784\n",
      "95 0.002753500193190321 0.3436701679055687\n",
      "96 0.002749703800303492 0.3464198717058722\n",
      "97 0.0027475517570587373 0.34916742346293095\n",
      "98 0.002745465626263277 0.3519128890891942\n",
      "99 0.0027417531850808664 0.35465464227427507\n",
      "100 0.002740214055383296 0.35739485632965834\n",
      "101 0.002738613324243591 0.3601334696539019\n",
      "102 0.002737936006340332 0.36287140566024223\n",
      "103 0.002735241363420309 0.3656066470236625\n",
      "104 0.0027335637486873886 0.3683402107723499\n",
      "105 0.002730362227596002 0.3710705729999459\n",
      "106 0.002727269523983042 0.37379784252392895\n",
      "107 0.0027244113333376565 0.3765222538572666\n",
      "108 0.0027206676428652606 0.3792429215001319\n",
      "109 0.0027178079951542763 0.38196072949528614\n",
      "110 0.0027170440837688895 0.384677773579055\n",
      "111 0.002715264953400079 0.3873930385324551\n",
      "112 0.002711874354272434 0.39010491288672755\n",
      "113 0.0027098977405686582 0.39281481062729623\n",
      "114 0.002709239919166154 0.3955240505464624\n",
      "115 0.0027060566061563826 0.39823010715261875\n",
      "116 0.0027036037708939374 0.4009337109235127\n",
      "117 0.002701932863551296 0.403635643787064\n",
      "118 0.0026985456140803054 0.4063341894011443\n",
      "119 0.002696281667319947 0.40903047106846424\n",
      "120 0.002694959767792063 0.4117254308362563\n",
      "121 0.0026915562410802125 0.4144169870773365\n",
      "122 0.0026888779583976626 0.41710586503573416\n",
      "123 0.002684250028934002 0.4197901150646682\n",
      "124 0.00268301282176386 0.42247312788643204\n",
      "125 0.002680120592070255 0.4251532484785023\n",
      "126 0.0026792800548964112 0.4278325285333987\n",
      "127 0.0026786890819853995 0.4305112176153841\n",
      "128 0.002678097882198932 0.433189315497583\n",
      "129 0.0026746965937166117 0.4358640120912996\n",
      "130 0.0026721435299438176 0.43853615562124343\n",
      "131 0.0026693449554737454 0.44120550057671715\n",
      "132 0.0026655356409282056 0.44387103621764534\n",
      "133 0.0026640399038666985 0.44653507612151205\n",
      "134 0.0026631674858688366 0.44919824360738086\n",
      "135 0.0026609844965817735 0.4518592281039626\n",
      "136 0.002657930804719727 0.45451715890868233\n",
      "137 0.0026570191463935965 0.45717417805507593\n",
      "138 0.0026549976000380584 0.459829175655114\n",
      "139 0.002654711698509314 0.46248388735362334\n",
      "140 0.002653129186832598 0.4651370165404559\n",
      "141 0.0026504291590571283 0.467787445699513\n",
      "142 0.0026485602210773273 0.47043600592059037\n",
      "143 0.0026468281080128785 0.47308283402860324\n",
      "144 0.0026454908589116557 0.4757283248875149\n",
      "145 0.00264280945505154 0.4783711343425664\n",
      "146 0.0026398383560085905 0.481010972698575\n",
      "147 0.0026379100773875007 0.4836488827759625\n",
      "148 0.0026353338845907497 0.48628421666055327\n",
      "149 0.0026341563708441843 0.48891837303139746\n",
      "150 0.0026334091075816642 0.4915517821389791\n",
      "151 0.0026320955209019354 0.49418387765988103\n",
      "152 0.0026301228670287044 0.4968140005269097\n",
      "153 0.002628245224480297 0.49944224575139\n",
      "154 0.002626012937113472 0.5020682586885035\n",
      "155 0.00262450021833368 0.5046927589068372\n",
      "156 0.0026215576920502765 0.5073143165988875\n",
      "157 0.0026203602123411195 0.5099346768112286\n",
      "158 0.0026180154216063796 0.512552692232835\n",
      "159 0.0026158415322418685 0.5151685337650768\n",
      "160 0.0026149776940398765 0.5177835114591166\n",
      "161 0.0026147600832210263 0.5203982715423376\n",
      "162 0.0026126814151132658 0.5230109529574509\n",
      "163 0.0026114207101296857 0.5256223736675806\n",
      "164 0.0026077851295853785 0.528230158797166\n",
      "165 0.0026067195743298185 0.5308368783714957\n",
      "166 0.002604633243511774 0.5334415116150075\n",
      "167 0.0026022817167334514 0.536043793331741\n",
      "168 0.002601927598247495 0.5386457209299885\n",
      "169 0.002600239818758181 0.5412459607487468\n",
      "170 0.002599378148878471 0.5438453388976252\n",
      "171 0.0025974884878925517 0.5464428273855177\n",
      "172 0.002596302416319596 0.5490391298018373\n",
      "173 0.002593337374802824 0.5516324671766402\n",
      "174 0.002592665805060922 0.5542251329817011\n",
      "175 0.0025911233891718717 0.556816256370873\n",
      "176 0.0025902361972326257 0.5594064925681056\n",
      "177 0.0025900344243542754 0.5619965269924598\n",
      "178 0.0025887336194545672 0.5645852606119144\n",
      "179 0.0025877439033430458 0.5671730045152574\n",
      "180 0.002585670738437417 0.5697586752536948\n",
      "181 0.0025847757204208854 0.5723434509741158\n",
      "182 0.002584280772397613 0.5749277317465133\n",
      "183 0.0025817130384636275 0.577509444784977\n",
      "184 0.0025803268000294754 0.5800897715850065\n",
      "185 0.0025793986784725595 0.5826691702634791\n",
      "186 0.002579224036815461 0.5852483943002945\n",
      "187 0.002577380604844618 0.5878257749051391\n",
      "188 0.0025770452617061494 0.5904028201668452\n",
      "189 0.0025766524047261485 0.5929794725715714\n",
      "190 0.0025757157649295907 0.5955551883365009\n",
      "191 0.002573108680392465 0.5981282970168934\n",
      "192 0.002572415321501314 0.6007007123383947\n",
      "193 0.0025703739395624603 0.6032710862779572\n",
      "194 0.0025695437039751066 0.6058406299819323\n",
      "195 0.0025685770333717032 0.608409207015304\n",
      "196 0.0025677326836649923 0.6109769396989689\n",
      "197 0.002567186180736944 0.6135441258797059\n",
      "198 0.0025661678150982695 0.6161102936948041\n",
      "199 0.002564945425583109 0.6186752391203871\n",
      "200 0.002564093844293336 0.6212393329646805\n",
      "201 0.0025632203999937037 0.6238025533646742\n",
      "202 0.0025609501886747423 0.6263635035533489\n",
      "203 0.0025593603245771565 0.6289228638779261\n",
      "204 0.0025579923406785056 0.6314808562186046\n",
      "205 0.002556978657108825 0.6340378348757134\n",
      "206 0.0025552462426529 0.6365930811183663\n",
      "207 0.0025549863773756125 0.6391480674957419\n",
      "208 0.002553422239702214 0.6417014897354442\n",
      "209 0.002551817659713032 0.6442533073951572\n",
      "210 0.0025495008466949343 0.6468028082418521\n",
      "211 0.0025489485868955687 0.6493517568287477\n",
      "212 0.0025465595276550936 0.6518983163564028\n",
      "213 0.0025450978043660734 0.6544434141607689\n",
      "214 0.0025422562537771704 0.656985670414546\n",
      "215 0.0025418668617602064 0.6595275372763062\n",
      "216 0.002539957968220309 0.6620674952445265\n",
      "217 0.0025392012696127783 0.6646066965141393\n",
      "218 0.002537903629401663 0.6671446001435409\n",
      "219 0.0025339520179657638 0.6696785521615067\n",
      "220 0.002533556649452572 0.6722121088109593\n",
      "221 0.0025320019338172044 0.6747441107447765\n",
      "222 0.0025316327589843487 0.6772757435037609\n",
      "223 0.002527174336933847 0.6798029178406947\n",
      "224 0.0025242141474337166 0.6823271319881284\n",
      "225 0.002522225505787872 0.6848493574939163\n",
      "226 0.0025216641051971295 0.6873710215991135\n",
      "227 0.0025180399258803916 0.6898890615249939\n",
      "228 0.0025171919252898354 0.6924062534502837\n",
      "229 0.002516430114748877 0.6949226835650326\n",
      "230 0.0025145731428780904 0.6974372567079107\n",
      "231 0.0025137706011074223 0.6999510273090181\n",
      "232 0.002510021220101629 0.7024610485291197\n",
      "233 0.00250788385851137 0.7049689323876311\n",
      "234 0.0025057893387445316 0.7074747217263757\n",
      "235 0.0025030575040138254 0.7099777792303895\n",
      "236 0.0025017220296309523 0.7124795012600205\n",
      "237 0.0025003196272240075 0.7149798208872444\n",
      "238 0.002496324159069425 0.7174761450463139\n",
      "239 0.0024946043513379055 0.7199707493976517\n",
      "240 0.0024928445393531044 0.7224635939370048\n",
      "241 0.002492293569772672 0.7249558875067774\n",
      "242 0.0024906423204843027 0.7274465298272618\n",
      "243 0.002489412960458682 0.7299359427877204\n",
      "244 0.0024871952664726263 0.7324231380541931\n",
      "245 0.002484586483845744 0.7349077245380389\n",
      "246 0.0024821512284347487 0.7373898757664736\n",
      "247 0.0024786317211909544 0.7398685074876646\n",
      "248 0.002477850210579365 0.742346357698244\n",
      "249 0.0024743522339531728 0.7448207099321972\n",
      "250 0.002474013605824952 0.7472947235380222\n",
      "251 0.002470935863997184 0.7497656594020193\n",
      "252 0.0024699210244455653 0.7522355804264649\n",
      "253 0.002466809068866905 0.7547023894953317\n",
      "254 0.00246354431362045 0.7571659338089523\n",
      "255 0.0024619934779598965 0.7596279272869122\n",
      "256 0.0024607596526339927 0.7620886869395462\n",
      "257 0.002459393661112555 0.7645480806006588\n",
      "258 0.0024547554301848824 0.7670028360308437\n",
      "259 0.0024525963559304744 0.7694554323867742\n",
      "260 0.0024470661352915778 0.7719024985220657\n",
      "261 0.0024466451414323184 0.774349143663498\n",
      "262 0.0024442173633808933 0.7767933610268789\n",
      "263 0.0024428401614557567 0.7792362011883347\n",
      "264 0.002441002415476848 0.7816772036038115\n",
      "265 0.0024389206168222125 0.7841161242206337\n",
      "266 0.002436080471617551 0.7865522046922513\n",
      "267 0.0024338474166275327 0.7889860521088788\n",
      "268 0.0024304289962751506 0.791416481105154\n",
      "269 0.002430101055543579 0.7938465821606975\n",
      "270 0.0024281414369839854 0.7962747235976815\n",
      "271 0.0024265784193984803 0.79870130201708\n",
      "272 0.0024225608658793095 0.8011238628829593\n",
      "273 0.0024203898809821945 0.8035442527639415\n",
      "274 0.002419470689793749 0.8059637234537352\n",
      "275 0.0024171023347795777 0.8083808257885148\n",
      "276 0.002412200726613181 0.810793026515128\n",
      "277 0.002410213572081141 0.8132032400872091\n",
      "278 0.0024074753147773553 0.8156107154019865\n",
      "279 0.0024048450367702705 0.8180155604387568\n",
      "280 0.002403057752701747 0.8204186181914586\n",
      "281 0.002399721216526218 0.8228183394079848\n",
      "282 0.002399429684838289 0.8252177690928231\n",
      "283 0.0023971918326270735 0.8276149609254502\n",
      "284 0.002396906428538372 0.8300118673539886\n",
      "285 0.0023900315077691214 0.8324018988617577\n",
      "286 0.0023869320585644337 0.8347888309203222\n",
      "287 0.002383879993154036 0.8371727109134762\n",
      "288 0.002382995843835865 0.8395557067573121\n",
      "289 0.0023760875471783606 0.8419317943044904\n",
      "290 0.002375360086200881 0.8443071543906913\n",
      "291 0.0023718874966799134 0.8466790418873712\n",
      "292 0.0023705141250956077 0.8490495560124668\n",
      "293 0.0023676439799764615 0.8514171999924433\n",
      "294 0.0023638863742156385 0.8537810863666588\n",
      "295 0.002361783641744549 0.8561428700084034\n",
      "296 0.00236045862056378 0.8585033286289672\n",
      "297 0.0023571976537699146 0.8608605262827371\n",
      "298 0.002355442168758428 0.8632159684514955\n",
      "299 0.0023521929052999664 0.8655681613567955\n",
      "300 0.0023505653077006802 0.8679187266644962\n",
      "301 0.0023483823065694417 0.8702671089710656\n",
      "302 0.002345729445677975 0.8726128384167436\n",
      "303 0.0023405579429832 0.8749533963597268\n",
      "304 0.002335925707568769 0.8772893220672956\n",
      "305 0.0023317227105617852 0.8796210447778574\n",
      "306 0.002329275315959384 0.8819503200938168\n",
      "307 0.0023266397943488633 0.8842769598881657\n",
      "308 0.0023229621705458045 0.8865999220587115\n",
      "309 0.0023207258226417803 0.8889206478813533\n",
      "310 0.002319076889405711 0.891239724770759\n",
      "311 0.0023111326896563785 0.8935508574604153\n",
      "312 0.0023083784318139347 0.8958592358922293\n",
      "313 0.002304773527518826 0.898164009419748\n",
      "314 0.002301100012531709 0.9004651094322798\n",
      "315 0.0022995164073537915 0.9027646258396336\n",
      "316 0.002297120178085904 0.9050617460177195\n",
      "317 0.0022908966396228687 0.9073526426573424\n",
      "318 0.0022895041938830905 0.9096421468512255\n",
      "319 0.002286464540710379 0.9119286113919358\n",
      "320 0.0022791011665461948 0.914207712558482\n",
      "321 0.002275795376382 0.916483507934864\n",
      "322 0.0022723758373746714 0.9187558837722387\n",
      "323 0.0022667521791275994 0.9210226359513664\n",
      "324 0.002257218041397577 0.9232798539927639\n",
      "325 0.002256261500473499 0.9255361154932374\n",
      "326 0.002252643413987823 0.9277887589072252\n",
      "327 0.0022495484364607765 0.930038307343686\n",
      "328 0.0022474256131504344 0.9322857329568364\n",
      "329 0.0022367340752948656 0.9345224670321313\n",
      "330 0.002232502371668799 0.9367549694038001\n",
      "331 0.0022272478839274537 0.9389822172877276\n",
      "332 0.0022196507223123502 0.9412018680100399\n",
      "333 0.0022131689973344144 0.9434150370073743\n",
      "334 0.0022027669416994533 0.9456178039490737\n",
      "335 0.0021987539451101745 0.9478165578941838\n",
      "336 0.002190921511356428 0.9500074794055403\n",
      "337 0.002188256678072188 0.9521957360836125\n",
      "338 0.002172481434344237 0.9543682175179568\n",
      "339 0.002161691180860015 0.9565299086988168\n",
      "340 0.0021449838192761747 0.958674892518093\n",
      "341 0.002138410507289266 0.9608133030253823\n",
      "342 0.0021274332802955365 0.9629407363056778\n",
      "343 0.0021224250352738423 0.9650631613409516\n",
      "344 0.002107201915165768 0.9671703632561174\n",
      "345 0.002093666964479012 0.9692640302205964\n",
      "346 0.0020863513458972676 0.9713503815664937\n",
      "347 0.002066691260982195 0.9734170728274759\n",
      "348 0.002046145356582324 0.9754632181840582\n",
      "349 0.0020285882288649804 0.9774918064129232\n",
      "350 0.001980196039407435 0.9794720024523307\n",
      "351 0.0019708654837146244 0.9814428679360453\n",
      "352 0.0019284172676511146 0.9833712852036964\n",
      "353 0.0018981472473441072 0.9852694324510406\n",
      "354 0.0018853220138905277 0.9871547544649312\n",
      "355 0.0018592707276696243 0.9890140251926008\n",
      "356 0.0017235216319794859 0.9907375468245804\n",
      "357 0.0016840125670349064 0.9924215593916152\n",
      "358 0.0016422612152910366 0.9940638206069062\n",
      "359 0.0015283730659030078 0.9955921936728093\n",
      "360 0.0014650282818554447 0.9970572219546647\n",
      "361 0.0014541079005764386 0.9985113298552412\n",
      "362 0.0009448030132557739 0.9994561328684969\n",
      "363 0.00035283721303704774 0.9998089700815339\n",
      "364 7.852680473075966e-05 0.9998874968862647\n",
      "365 7.354746020054494e-05 0.9999610443464652\n",
      "366 3.193811095528875e-05 0.9999929824574204\n",
      "367 7.017542579497289e-06 0.9999999999999999\n",
      "368 1.516610679666815e-32 0.9999999999999999\n",
      "369 5.438820006802835e-33 0.9999999999999999\n",
      "370 3.013725494736443e-33 0.9999999999999999\n",
      "371 2.879688480303421e-33 0.9999999999999999\n",
      "372 2.7711913385874686e-33 0.9999999999999999\n",
      "373 1.4359826871213317e-33 0.9999999999999999\n",
      "374 1.279606522118285e-33 0.9999999999999999\n",
      "375 1.2600431004963223e-33 0.9999999999999999\n",
      "376 1.201677387193262e-33 0.9999999999999999\n",
      "377 8.244953404766717e-34 0.9999999999999999\n",
      "378 7.653601212331105e-34 0.9999999999999999\n",
      "379 7.265035283723341e-34 0.9999999999999999\n",
      "380 4.739965395294452e-34 0.9999999999999999\n",
      "381 3.1809575574183803e-34 0.9999999999999999\n",
      "382 2.783463794072535e-34 0.9999999999999999\n",
      "383 2.398679576107179e-34 0.9999999999999999\n",
      "384 1.861411643098004e-34 0.9999999999999999\n",
      "385 1.2719460134365023e-34 0.9999999999999999\n",
      "386 1.2719460134365023e-34 0.9999999999999999\n",
      "387 9.45100449915426e-35 0.9999999999999999\n",
      "388 8.978345258779049e-35 0.9999999999999999\n",
      "389 5.085419077530828e-35 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "CumSum_PCA = 0\n",
    "feature_no = list(range(1,390))\n",
    "\n",
    "print(\"Cumulative Variance:\")\n",
    "for i in range(len(components_variance_PCA)):\n",
    "    CumSum_PCA = CumSum_PCA + components_variance_PCA[i]\n",
    "    print(i+1, components_variance_PCA[i], CumSum_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visual Exploration of Training Set\n",
    "\n",
    "plt.scatter(feature_no,components_variance_PCA,color='red')\n",
    "plt.xlabel('Principal Component Number')\n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.ylim(0,0.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of principal component analysis show that only two variables explain more than 1% of the variance. If we were to reduce the number of components to 336, we would account for 95% of the variance in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pcaObj = PCA(n_components=336)\n",
    "X_PCA_reduced = pcaObj.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#K-fold Cross Validation on PCA set using Logistic Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "modelAccuracies_logreg_PCA = cross_val_score(estimator=logRegObj, X=X_PCA_reduced, y=y2, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression post-PCA\n",
      "Number of components\n",
      "336\n",
      "Model Accuracy mean\n",
      "0.8197172681539808\n",
      "Model Accuracy SD\n",
      "0.05879634928921386\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression post-PCA\")\n",
    "print(\"Number of components\")\n",
    "print(\"336\")\n",
    "print(\"Model Accuracy mean\")\n",
    "print(modelAccuracies_logreg_PCA.mean())\n",
    "print(\"Model Accuracy SD\")\n",
    "print(modelAccuracies_logreg_PCA.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#Applying LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "ldaObj = LDA(n_components=None)\n",
    "X_LDA= ldaObj.fit_transform(X_std, y2)\n",
    "components_variance_LDA = ldaObj.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis should not be used on this dataset because the variables are collinear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
